{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST CNN\n",
    "\n",
    "TODO :\n",
    "1. [Create validation and sample sets](#Create-validation-and-sample-sets)\n",
    "2. [Rearrange image files into new directories](#Rearrange-image-files-into-new-directories)\n",
    "3. [Fine-tuning](#Fine-tuning)\n",
    "4. [Training](#Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Conv2D, Dense, Dropout, Flatten, Lambda, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/mnist/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = train.drop('label', axis=1)\n",
    "y_train = train.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('./data/mnist/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(-1, 1, 28, 28)\n",
    "X_test = X_test.values.reshape(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 1, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot(y, num_classes=None):\n",
    "    \"\"\"Converts a class vector (integers) to binary class matrix.\n",
    "    E.g. for use with categorical_crossentropy.\n",
    "    # Arguments\n",
    "        y: class vector to be converted into a matrix\n",
    "            (integers from 0 to num_classes).\n",
    "        num_classes: total number of classes.\n",
    "    # Returns\n",
    "        A binary matrix representation of the input.\n",
    "    \"\"\"\n",
    "    y = np.array(y, dtype='int').ravel()\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes))\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    return categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y_train = onehot(y_train, num_classes=10)\n",
    "Y_val = onehot(y_val, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_x = X_train.mean().astype(np.float32)\n",
    "std_x = X_train.std().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_input(x): return (x - mean_x) / std_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        Conv2D(32,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(32,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model():\n",
    "    model = get_model()\n",
    "    model.fit_generator(batches, batches.N, nb_epoch=1, validation_data=val_batches, nb_val_samples=val_batches.N)\n",
    "    model.optimizer.lr = 0.1\n",
    "    model.fit_generator(batches, batches.N, nb_epoch=4, validation_data=val_batches, nb_val_samples=val_batches.N)\n",
    "    model.optimizer.lr = 0.01\n",
    "    model.fit_generator(batches, batches.N, nb_epoch=8, validation_data=val_batches, nb_val_samples=val_batches.N)\n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(batches, batches.N, nb_epoch=8, validation_data=val_batches, nb_val_samples=val_batches.N)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(\n",
    "    rotation_range=12, \n",
    "    width_shift_range=0.1, \n",
    "    shear_range=0.3,\n",
    "    height_shift_range=0.1, \n",
    "    zoom_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batches = gen.flow(X_train, Y_train, batch_size=64)\n",
    "val_batches = gen.flow(X_val, Y_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "33600/33600 [==============================] - 36s - loss: 0.3542 - acc: 0.8920 - val_loss: 0.2628 - val_acc: 0.9156\n",
      "Epoch 1/4\n",
      "33600/33600 [==============================] - 36s - loss: 0.1393 - acc: 0.9571 - val_loss: 0.2178 - val_acc: 0.9325\n",
      "Epoch 2/4\n",
      "33600/33600 [==============================] - 35s - loss: 0.1046 - acc: 0.9683 - val_loss: 0.0764 - val_acc: 0.9743\n",
      "Epoch 3/4\n",
      "33600/33600 [==============================] - 35s - loss: 0.0910 - acc: 0.9716 - val_loss: 0.0565 - val_acc: 0.9801\n",
      "Epoch 4/4\n",
      "33600/33600 [==============================] - 35s - loss: 0.0855 - acc: 0.9741 - val_loss: 0.0709 - val_acc: 0.9779\n",
      "Epoch 1/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0743 - acc: 0.9776 - val_loss: 0.0723 - val_acc: 0.9746\n",
      "Epoch 2/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0719 - acc: 0.9776 - val_loss: 0.0769 - val_acc: 0.9749\n",
      "Epoch 3/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0687 - acc: 0.9786 - val_loss: 0.0626 - val_acc: 0.9802\n",
      "Epoch 4/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0640 - acc: 0.9799 - val_loss: 0.0614 - val_acc: 0.9800\n",
      "Epoch 5/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0575 - acc: 0.9824 - val_loss: 0.0384 - val_acc: 0.9873\n",
      "Epoch 6/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0628 - acc: 0.9807 - val_loss: 0.0449 - val_acc: 0.9865\n",
      "Epoch 7/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0553 - acc: 0.9830 - val_loss: 0.0421 - val_acc: 0.9874\n",
      "Epoch 8/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0524 - acc: 0.9843 - val_loss: 0.0396 - val_acc: 0.9868\n",
      "Epoch 1/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0528 - acc: 0.9837 - val_loss: 0.0441 - val_acc: 0.9851\n",
      "Epoch 2/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0558 - acc: 0.9830 - val_loss: 0.0356 - val_acc: 0.9883\n",
      "Epoch 3/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0500 - acc: 0.9843 - val_loss: 0.0369 - val_acc: 0.9885\n",
      "Epoch 4/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0483 - acc: 0.9856 - val_loss: 0.0515 - val_acc: 0.9851\n",
      "Epoch 5/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0462 - acc: 0.9857 - val_loss: 0.0475 - val_acc: 0.9865\n",
      "Epoch 6/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0453 - acc: 0.9858 - val_loss: 0.0367 - val_acc: 0.9879\n",
      "Epoch 7/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0459 - acc: 0.9856 - val_loss: 0.0381 - val_acc: 0.9879\n",
      "Epoch 8/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0447 - acc: 0.9863 - val_loss: 0.0269 - val_acc: 0.9908\n",
      "Epoch 1/1\n",
      "33600/33600 [==============================] - 35s - loss: 0.3511 - acc: 0.8932 - val_loss: 0.1641 - val_acc: 0.9512\n",
      "Epoch 1/4\n",
      "33600/33600 [==============================] - 35s - loss: 0.1389 - acc: 0.9578 - val_loss: 0.0868 - val_acc: 0.9727\n",
      "Epoch 2/4\n",
      "33600/33600 [==============================] - 35s - loss: 0.1037 - acc: 0.9675 - val_loss: 0.0781 - val_acc: 0.9751\n",
      "Epoch 3/4\n",
      "33600/33600 [==============================] - 36s - loss: 0.0918 - acc: 0.9715 - val_loss: 0.0701 - val_acc: 0.9782\n",
      "Epoch 4/4\n",
      "33600/33600 [==============================] - 35s - loss: 0.0827 - acc: 0.9742 - val_loss: 0.0829 - val_acc: 0.9743\n",
      "Epoch 1/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0771 - acc: 0.9769 - val_loss: 0.0590 - val_acc: 0.9796\n",
      "Epoch 2/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0714 - acc: 0.9781 - val_loss: 0.0757 - val_acc: 0.9775\n",
      "Epoch 3/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0645 - acc: 0.9805 - val_loss: 0.0525 - val_acc: 0.9824\n",
      "Epoch 4/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0665 - acc: 0.9794 - val_loss: 0.0656 - val_acc: 0.9808\n",
      "Epoch 5/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0638 - acc: 0.9803 - val_loss: 0.0594 - val_acc: 0.9818\n",
      "Epoch 6/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0588 - acc: 0.9821 - val_loss: 0.0451 - val_acc: 0.9854\n",
      "Epoch 7/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0601 - acc: 0.9823 - val_loss: 0.0473 - val_acc: 0.9844\n",
      "Epoch 8/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0535 - acc: 0.9836 - val_loss: 0.0503 - val_acc: 0.9867\n",
      "Epoch 1/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0536 - acc: 0.9836 - val_loss: 0.0443 - val_acc: 0.9862\n",
      "Epoch 2/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0493 - acc: 0.9846 - val_loss: 0.0512 - val_acc: 0.9865\n",
      "Epoch 3/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0481 - acc: 0.9852 - val_loss: 0.0465 - val_acc: 0.9855\n",
      "Epoch 4/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0495 - acc: 0.9846 - val_loss: 0.0361 - val_acc: 0.9892\n",
      "Epoch 5/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0480 - acc: 0.9853 - val_loss: 0.0394 - val_acc: 0.9875\n",
      "Epoch 6/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0445 - acc: 0.9857 - val_loss: 0.0401 - val_acc: 0.9865\n",
      "Epoch 7/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0450 - acc: 0.9868 - val_loss: 0.0359 - val_acc: 0.9901\n",
      "Epoch 8/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0430 - acc: 0.9869 - val_loss: 0.0410 - val_acc: 0.9876\n",
      "Epoch 1/1\n",
      "33600/33600 [==============================] - 35s - loss: 0.3621 - acc: 0.8918 - val_loss: 0.1729 - val_acc: 0.9476\n",
      "Epoch 1/4\n",
      "33600/33600 [==============================] - 35s - loss: 0.1332 - acc: 0.9592 - val_loss: 0.1061 - val_acc: 0.9677\n",
      "Epoch 2/4\n",
      "33600/33600 [==============================] - 36s - loss: 0.1074 - acc: 0.9676 - val_loss: 0.1076 - val_acc: 0.9651\n",
      "Epoch 3/4\n",
      "33600/33600 [==============================] - 35s - loss: 0.0908 - acc: 0.9725 - val_loss: 0.0719 - val_acc: 0.9765\n",
      "Epoch 4/4\n",
      "33600/33600 [==============================] - 35s - loss: 0.0811 - acc: 0.9750 - val_loss: 0.0702 - val_acc: 0.9777\n",
      "Epoch 1/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0773 - acc: 0.9753 - val_loss: 0.0689 - val_acc: 0.9786\n",
      "Epoch 2/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0687 - acc: 0.9780 - val_loss: 0.0589 - val_acc: 0.9820\n",
      "Epoch 3/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0666 - acc: 0.9792 - val_loss: 0.0500 - val_acc: 0.9846\n",
      "Epoch 4/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0619 - acc: 0.9810 - val_loss: 0.0627 - val_acc: 0.9812\n",
      "Epoch 5/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0657 - acc: 0.9799 - val_loss: 0.0524 - val_acc: 0.9843\n",
      "Epoch 6/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0578 - acc: 0.9821 - val_loss: 0.0432 - val_acc: 0.9875\n",
      "Epoch 7/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0578 - acc: 0.9821 - val_loss: 0.0451 - val_acc: 0.9852\n",
      "Epoch 8/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0552 - acc: 0.9840 - val_loss: 0.0400 - val_acc: 0.9880\n",
      "Epoch 1/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0482 - acc: 0.9849 - val_loss: 0.0450 - val_acc: 0.9858\n",
      "Epoch 2/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0499 - acc: 0.9841 - val_loss: 0.0405 - val_acc: 0.9862\n",
      "Epoch 3/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0501 - acc: 0.9852 - val_loss: 0.0431 - val_acc: 0.9858\n",
      "Epoch 4/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0474 - acc: 0.9847 - val_loss: 0.0459 - val_acc: 0.9843\n",
      "Epoch 5/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0489 - acc: 0.9844 - val_loss: 0.0401 - val_acc: 0.9883\n",
      "Epoch 6/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0427 - acc: 0.9876 - val_loss: 0.0436 - val_acc: 0.9868\n",
      "Epoch 7/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0433 - acc: 0.9871 - val_loss: 0.0314 - val_acc: 0.9899\n",
      "Epoch 8/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0437 - acc: 0.9870 - val_loss: 0.0569 - val_acc: 0.9826\n",
      "Epoch 1/1\n",
      "33600/33600 [==============================] - 35s - loss: 0.3564 - acc: 0.8914 - val_loss: 0.2714 - val_acc: 0.9198\n",
      "Epoch 1/4\n",
      "33600/33600 [==============================] - 35s - loss: 0.1392 - acc: 0.9557 - val_loss: 0.0865 - val_acc: 0.9739\n",
      "Epoch 2/4\n",
      "33600/33600 [==============================] - 35s - loss: 0.1050 - acc: 0.9678 - val_loss: 0.0950 - val_acc: 0.9731\n",
      "Epoch 3/4\n",
      "33600/33600 [==============================] - 35s - loss: 0.0856 - acc: 0.9734 - val_loss: 0.0645 - val_acc: 0.9802\n",
      "Epoch 4/4\n",
      "33600/33600 [==============================] - 35s - loss: 0.0824 - acc: 0.9740 - val_loss: 0.0667 - val_acc: 0.9779\n",
      "Epoch 1/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0731 - acc: 0.9784 - val_loss: 0.0494 - val_acc: 0.9862\n",
      "Epoch 2/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0721 - acc: 0.9773 - val_loss: 0.0553 - val_acc: 0.9831\n",
      "Epoch 3/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0692 - acc: 0.9780 - val_loss: 0.0596 - val_acc: 0.9817\n",
      "Epoch 4/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0649 - acc: 0.9801 - val_loss: 0.0526 - val_acc: 0.9837\n",
      "Epoch 5/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0629 - acc: 0.9803 - val_loss: 0.0458 - val_acc: 0.9836\n",
      "Epoch 6/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0585 - acc: 0.9819 - val_loss: 0.0425 - val_acc: 0.9870\n",
      "Epoch 7/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0552 - acc: 0.9832 - val_loss: 0.0452 - val_acc: 0.9867\n",
      "Epoch 8/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0528 - acc: 0.9843 - val_loss: 0.0484 - val_acc: 0.9848\n",
      "Epoch 1/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0507 - acc: 0.9839 - val_loss: 0.0516 - val_acc: 0.9846\n",
      "Epoch 2/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0516 - acc: 0.9842 - val_loss: 0.0481 - val_acc: 0.9858\n",
      "Epoch 3/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0507 - acc: 0.9839 - val_loss: 0.0364 - val_acc: 0.9879\n",
      "Epoch 4/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0469 - acc: 0.9852 - val_loss: 0.0511 - val_acc: 0.9845\n",
      "Epoch 5/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0437 - acc: 0.9859 - val_loss: 0.0335 - val_acc: 0.9894\n",
      "Epoch 6/8\n",
      "33600/33600 [==============================] - 38s - loss: 0.0443 - acc: 0.9870 - val_loss: 0.0344 - val_acc: 0.9880\n",
      "Epoch 7/8\n",
      "33600/33600 [==============================] - 42s - loss: 0.0458 - acc: 0.9858 - val_loss: 0.0451 - val_acc: 0.9874\n",
      "Epoch 8/8\n",
      "33600/33600 [==============================] - 45s - loss: 0.0450 - acc: 0.9865 - val_loss: 0.0387 - val_acc: 0.9882\n",
      "Epoch 1/1\n",
      "33600/33600 [==============================] - 36s - loss: 0.3602 - acc: 0.8915 - val_loss: 0.3799 - val_acc: 0.8890\n",
      "Epoch 1/4\n",
      "33600/33600 [==============================] - 36s - loss: 0.1326 - acc: 0.9597 - val_loss: 0.0915 - val_acc: 0.9714\n",
      "Epoch 2/4\n",
      "33600/33600 [==============================] - 35s - loss: 0.1088 - acc: 0.9665 - val_loss: 0.0685 - val_acc: 0.9781\n",
      "Epoch 3/4\n",
      "33600/33600 [==============================] - 35s - loss: 0.0926 - acc: 0.9717 - val_loss: 0.0756 - val_acc: 0.9765\n",
      "Epoch 4/4\n",
      "33600/33600 [==============================] - 36s - loss: 0.0833 - acc: 0.9742 - val_loss: 0.0621 - val_acc: 0.9800\n",
      "Epoch 1/8\n",
      "33600/33600 [==============================] - 36s - loss: 0.0772 - acc: 0.9766 - val_loss: 0.0640 - val_acc: 0.9788\n",
      "Epoch 2/8\n",
      "33600/33600 [==============================] - 36s - loss: 0.0728 - acc: 0.9766 - val_loss: 0.0474 - val_acc: 0.9864\n",
      "Epoch 3/8\n",
      "33600/33600 [==============================] - 36s - loss: 0.0702 - acc: 0.9783 - val_loss: 0.0488 - val_acc: 0.9837\n",
      "Epoch 4/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0641 - acc: 0.9803 - val_loss: 0.0495 - val_acc: 0.9833\n",
      "Epoch 5/8\n",
      "33600/33600 [==============================] - 36s - loss: 0.0602 - acc: 0.9806 - val_loss: 0.0473 - val_acc: 0.9863\n",
      "Epoch 6/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0587 - acc: 0.9818 - val_loss: 0.0500 - val_acc: 0.9852\n",
      "Epoch 7/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0580 - acc: 0.9820 - val_loss: 0.0471 - val_acc: 0.9855\n",
      "Epoch 8/8\n",
      "33600/33600 [==============================] - 36s - loss: 0.0540 - acc: 0.9824 - val_loss: 0.0474 - val_acc: 0.9863\n",
      "Epoch 1/8\n",
      "33600/33600 [==============================] - 36s - loss: 0.0493 - acc: 0.9855 - val_loss: 0.0344 - val_acc: 0.9892\n",
      "Epoch 2/8\n",
      "33600/33600 [==============================] - 36s - loss: 0.0507 - acc: 0.9851 - val_loss: 0.0504 - val_acc: 0.9857\n",
      "Epoch 3/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0531 - acc: 0.9837 - val_loss: 0.0389 - val_acc: 0.9879\n",
      "Epoch 4/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0483 - acc: 0.9852 - val_loss: 0.0497 - val_acc: 0.9857\n",
      "Epoch 5/8\n",
      "33600/33600 [==============================] - 36s - loss: 0.0472 - acc: 0.9855 - val_loss: 0.0396 - val_acc: 0.9881\n",
      "Epoch 6/8\n",
      "33600/33600 [==============================] - 36s - loss: 0.0458 - acc: 0.9860 - val_loss: 0.0406 - val_acc: 0.9868\n",
      "Epoch 7/8\n",
      "33600/33600 [==============================] - 36s - loss: 0.0422 - acc: 0.9867 - val_loss: 0.0317 - val_acc: 0.9899\n",
      "Epoch 8/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0434 - acc: 0.9866 - val_loss: 0.0394 - val_acc: 0.9877\n",
      "Epoch 1/1\n",
      "33600/33600 [==============================] - 36s - loss: 0.3677 - acc: 0.8884 - val_loss: 0.1743 - val_acc: 0.9465\n",
      "Epoch 1/4\n",
      "33600/33600 [==============================] - 36s - loss: 0.1391 - acc: 0.9573 - val_loss: 0.1197 - val_acc: 0.9680\n",
      "Epoch 2/4\n",
      "33600/33600 [==============================] - 35s - loss: 0.1048 - acc: 0.9668 - val_loss: 0.0710 - val_acc: 0.9775\n",
      "Epoch 3/4\n",
      "33600/33600 [==============================] - 35s - loss: 0.0921 - acc: 0.9710 - val_loss: 0.0678 - val_acc: 0.9770\n",
      "Epoch 4/4\n",
      "33600/33600 [==============================] - 36s - loss: 0.0836 - acc: 0.9738 - val_loss: 0.0684 - val_acc: 0.9781\n",
      "Epoch 1/8\n",
      "33600/33600 [==============================] - 36s - loss: 0.0776 - acc: 0.9757 - val_loss: 0.0487 - val_acc: 0.9852\n",
      "Epoch 2/8\n",
      "33600/33600 [==============================] - 36s - loss: 0.0741 - acc: 0.9774 - val_loss: 0.0507 - val_acc: 0.9846\n",
      "Epoch 3/8\n",
      "33600/33600 [==============================] - 36s - loss: 0.0703 - acc: 0.9790 - val_loss: 0.0511 - val_acc: 0.9836\n",
      "Epoch 4/8\n",
      "33600/33600 [==============================] - 36s - loss: 0.0645 - acc: 0.9799 - val_loss: 0.0597 - val_acc: 0.9811\n",
      "Epoch 5/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0619 - acc: 0.9813 - val_loss: 0.0574 - val_acc: 0.9811\n",
      "Epoch 6/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0567 - acc: 0.9825 - val_loss: 0.0358 - val_acc: 0.9870\n",
      "Epoch 7/8\n",
      "33600/33600 [==============================] - 36s - loss: 0.0568 - acc: 0.9818 - val_loss: 0.0433 - val_acc: 0.9883\n",
      "Epoch 8/8\n",
      "33600/33600 [==============================] - 36s - loss: 0.0570 - acc: 0.9822 - val_loss: 0.0483 - val_acc: 0.9855\n",
      "Epoch 1/8\n",
      "33600/33600 [==============================] - 36s - loss: 0.0532 - acc: 0.9836 - val_loss: 0.0409 - val_acc: 0.9869\n",
      "Epoch 2/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0515 - acc: 0.9845 - val_loss: 0.0474 - val_acc: 0.9849\n",
      "Epoch 3/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0519 - acc: 0.9833 - val_loss: 0.0413 - val_acc: 0.9871\n",
      "Epoch 4/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0488 - acc: 0.9843 - val_loss: 0.0370 - val_acc: 0.9883\n",
      "Epoch 5/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0489 - acc: 0.9856 - val_loss: 0.0487 - val_acc: 0.9845\n",
      "Epoch 6/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0493 - acc: 0.9847 - val_loss: 0.0359 - val_acc: 0.9892\n",
      "Epoch 7/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0408 - acc: 0.9865 - val_loss: 0.0348 - val_acc: 0.9902\n",
      "Epoch 8/8\n",
      "33600/33600 [==============================] - 35s - loss: 0.0442 - acc: 0.9868 - val_loss: 0.0417 - val_acc: 0.9867\n"
     ]
    }
   ],
   "source": [
    "models = [fit_model() for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, m in enumerate(models):\n",
    "    m.save_weights('data/mnist/cnn-mnist-' + str(i) + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = np.array([m.predict(X_test, batch_size=256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 10)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.max(predictions, axis=0)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000,)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.argmax(labels, axis=1)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000,)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imageIds = np.arange(1, len(labels) + 1)\n",
    "imageIds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [2, 0],\n",
       "       [3, 9],\n",
       "       [4, 0],\n",
       "       [5, 3]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm = np.stack([imageIds, labels], axis=1)\n",
    "subm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_filename = 'subm.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(subm_filename, subm, fmt='%d,%d', header='ImageId,Label', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='subm.csv' target='_blank'>subm.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/nbs/deep-learning/subm.csv"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(subm_filename)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
