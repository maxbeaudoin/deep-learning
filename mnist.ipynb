{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST CNN\n",
    "\n",
    "TODO :\n",
    "1. [Create validation and sample sets](#Create-validation-and-sample-sets)\n",
    "2. [Rearrange image files into new directories](#Rearrange-image-files-into-new-directories)\n",
    "3. [Fine-tuning](#Fine-tuning)\n",
    "4. [Training](#Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Conv2D, Dense, Dropout, Flatten, Lambda, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/mnist/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = train.drop('label', axis=1)\n",
    "y_train = train.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('./data/mnist/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(-1, 1, 28, 28)\n",
    "X_test = X_test.values.reshape(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 1, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot(y, num_classes=None):\n",
    "    \"\"\"Converts a class vector (integers) to binary class matrix.\n",
    "    E.g. for use with categorical_crossentropy.\n",
    "    # Arguments\n",
    "        y: class vector to be converted into a matrix\n",
    "            (integers from 0 to num_classes).\n",
    "        num_classes: total number of classes.\n",
    "    # Returns\n",
    "        A binary matrix representation of the input.\n",
    "    \"\"\"\n",
    "    y = np.array(y, dtype='int').ravel()\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes))\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    return categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y_train = onehot(y_train, num_classes=10)\n",
    "#Y_val = onehot(y_val, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_x = X_train.mean().astype(np.float32)\n",
    "std_x = X_train.std().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_input(x): return (x - mean_x) / std_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        Conv2D(32,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(32,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64,3,3, activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(\n",
    "    rotation_range=12, \n",
    "    width_shift_range=0.1, \n",
    "    shear_range=0.3,\n",
    "    height_shift_range=0.1, \n",
    "    zoom_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batches = gen.flow(X_train, Y_train, batch_size=64)\n",
    "#val_batches = gen.flow(X_val, Y_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model():\n",
    "    model = get_model()\n",
    "    model.fit_generator(batches, batches.N, nb_epoch=1)#, validation_data=val_batches, nb_val_samples=val_batches.N)\n",
    "    model.optimizer.lr = 0.1\n",
    "    model.fit_generator(batches, batches.N, nb_epoch=4)#, validation_data=val_batches, nb_val_samples=val_batches.N)\n",
    "    model.optimizer.lr = 0.01\n",
    "    model.fit_generator(batches, batches.N, nb_epoch=8)#, validation_data=val_batches, nb_val_samples=val_batches.N)\n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(batches, batches.N, nb_epoch=8)#, validation_data=val_batches, nb_val_samples=val_batches.N)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "42000/42000 [==============================] - 41s - loss: 0.3302 - acc: 0.9011    \n",
      "Epoch 1/4\n",
      "42000/42000 [==============================] - 41s - loss: 0.1265 - acc: 0.9610    \n",
      "Epoch 2/4\n",
      "42000/42000 [==============================] - 41s - loss: 0.0986 - acc: 0.9683    \n",
      "Epoch 3/4\n",
      "42000/42000 [==============================] - 41s - loss: 0.0861 - acc: 0.9731    \n",
      "Epoch 4/4\n",
      "42000/42000 [==============================] - 41s - loss: 0.0764 - acc: 0.9772    \n",
      "Epoch 1/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0736 - acc: 0.9774    \n",
      "Epoch 2/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0706 - acc: 0.9781    \n",
      "Epoch 3/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0663 - acc: 0.9789    \n",
      "Epoch 4/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0611 - acc: 0.9807    \n",
      "Epoch 5/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0551 - acc: 0.9830    \n",
      "Epoch 6/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0577 - acc: 0.9817    \n",
      "Epoch 7/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0540 - acc: 0.9826    \n",
      "Epoch 8/8\n",
      "42000/42000 [==============================] - 40s - loss: 0.0525 - acc: 0.9835    \n",
      "Epoch 1/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0508 - acc: 0.9844    \n",
      "Epoch 2/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0523 - acc: 0.9844    \n",
      "Epoch 3/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0480 - acc: 0.9856    \n",
      "Epoch 4/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0472 - acc: 0.9856    \n",
      "Epoch 5/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0469 - acc: 0.9856    \n",
      "Epoch 6/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0435 - acc: 0.9865    \n",
      "Epoch 7/8\n",
      "42000/42000 [==============================] - 40s - loss: 0.0414 - acc: 0.9879    \n",
      "Epoch 8/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0426 - acc: 0.9871    \n",
      "Epoch 1/1\n",
      "42000/42000 [==============================] - 41s - loss: 0.3179 - acc: 0.9046    \n",
      "Epoch 1/4\n",
      "42000/42000 [==============================] - 41s - loss: 0.1292 - acc: 0.9595    \n",
      "Epoch 2/4\n",
      "42000/42000 [==============================] - 41s - loss: 0.0898 - acc: 0.9714    \n",
      "Epoch 3/4\n",
      "42000/42000 [==============================] - 41s - loss: 0.0890 - acc: 0.9730    \n",
      "Epoch 4/4\n",
      "42000/42000 [==============================] - 41s - loss: 0.0785 - acc: 0.9755    \n",
      "Epoch 1/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0706 - acc: 0.9782    \n",
      "Epoch 2/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0706 - acc: 0.9782    \n",
      "Epoch 3/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0644 - acc: 0.9805    \n",
      "Epoch 4/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0638 - acc: 0.9811    \n",
      "Epoch 5/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0545 - acc: 0.9828    \n",
      "Epoch 6/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0565 - acc: 0.9827    \n",
      "Epoch 7/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0545 - acc: 0.9839    \n",
      "Epoch 8/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0528 - acc: 0.9832    \n",
      "Epoch 1/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0505 - acc: 0.9847    \n",
      "Epoch 2/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0508 - acc: 0.9850    \n",
      "Epoch 3/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0442 - acc: 0.9865    \n",
      "Epoch 4/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0481 - acc: 0.9852    \n",
      "Epoch 5/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0440 - acc: 0.9869    \n",
      "Epoch 6/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0416 - acc: 0.9871    \n",
      "Epoch 7/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0399 - acc: 0.9877    \n",
      "Epoch 8/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0416 - acc: 0.9870    \n",
      "Epoch 1/1\n",
      "42000/42000 [==============================] - 41s - loss: 0.3006 - acc: 0.9086    \n",
      "Epoch 1/4\n",
      "42000/42000 [==============================] - 41s - loss: 0.1151 - acc: 0.9636    \n",
      "Epoch 2/4\n",
      "42000/42000 [==============================] - 41s - loss: 0.0995 - acc: 0.9691    \n",
      "Epoch 3/4\n",
      "42000/42000 [==============================] - 41s - loss: 0.0869 - acc: 0.9737    \n",
      "Epoch 4/4\n",
      "42000/42000 [==============================] - 41s - loss: 0.0755 - acc: 0.9775    \n",
      "Epoch 1/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0744 - acc: 0.9767    \n",
      "Epoch 2/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0652 - acc: 0.9802    \n",
      "Epoch 3/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0670 - acc: 0.9798    \n",
      "Epoch 4/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0609 - acc: 0.9818    \n",
      "Epoch 5/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0592 - acc: 0.9816    \n",
      "Epoch 6/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0562 - acc: 0.9828    \n",
      "Epoch 7/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0521 - acc: 0.9852    \n",
      "Epoch 8/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0514 - acc: 0.9834    \n",
      "Epoch 1/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0506 - acc: 0.9846    \n",
      "Epoch 2/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0506 - acc: 0.9843    \n",
      "Epoch 3/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0473 - acc: 0.9857    \n",
      "Epoch 4/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0462 - acc: 0.9861    \n",
      "Epoch 5/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0431 - acc: 0.9866    \n",
      "Epoch 6/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0431 - acc: 0.9870    \n",
      "Epoch 7/8\n",
      "42000/42000 [==============================] - 40s - loss: 0.0397 - acc: 0.9876    \n",
      "Epoch 8/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0398 - acc: 0.9874    \n",
      "Epoch 1/1\n",
      "42000/42000 [==============================] - 42s - loss: 0.3150 - acc: 0.9053    \n",
      "Epoch 1/4\n",
      "42000/42000 [==============================] - 42s - loss: 0.1251 - acc: 0.9610    \n",
      "Epoch 2/4\n",
      "42000/42000 [==============================] - 41s - loss: 0.0981 - acc: 0.9691    \n",
      "Epoch 3/4\n",
      "42000/42000 [==============================] - 41s - loss: 0.0855 - acc: 0.9730    \n",
      "Epoch 4/4\n",
      "42000/42000 [==============================] - 41s - loss: 0.0790 - acc: 0.9761    \n",
      "Epoch 1/8\n",
      "42000/42000 [==============================] - 42s - loss: 0.0704 - acc: 0.9792    \n",
      "Epoch 2/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0642 - acc: 0.9794    \n",
      "Epoch 3/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0608 - acc: 0.9809    \n",
      "Epoch 4/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0609 - acc: 0.9815    \n",
      "Epoch 5/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0590 - acc: 0.9819    \n",
      "Epoch 6/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0519 - acc: 0.9840    \n",
      "Epoch 7/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0530 - acc: 0.9835    \n",
      "Epoch 8/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0511 - acc: 0.9840    \n",
      "Epoch 1/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0495 - acc: 0.9849    \n",
      "Epoch 2/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0450 - acc: 0.9861    \n",
      "Epoch 3/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0454 - acc: 0.9860    \n",
      "Epoch 4/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0439 - acc: 0.9868    \n",
      "Epoch 5/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0447 - acc: 0.9859    \n",
      "Epoch 6/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0411 - acc: 0.9875    \n",
      "Epoch 7/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0424 - acc: 0.9867    \n",
      "Epoch 8/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0430 - acc: 0.9870    \n",
      "Epoch 1/1\n",
      "42000/42000 [==============================] - 41s - loss: 0.3112 - acc: 0.9063    \n",
      "Epoch 1/4\n",
      "42000/42000 [==============================] - 41s - loss: 0.1225 - acc: 0.9625    \n",
      "Epoch 2/4\n",
      "42000/42000 [==============================] - 41s - loss: 0.0983 - acc: 0.9699    \n",
      "Epoch 3/4\n",
      "42000/42000 [==============================] - 41s - loss: 0.0834 - acc: 0.9743    \n",
      "Epoch 4/4\n",
      "42000/42000 [==============================] - 41s - loss: 0.0795 - acc: 0.9760    \n",
      "Epoch 1/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0749 - acc: 0.9766    \n",
      "Epoch 2/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0665 - acc: 0.9797    \n",
      "Epoch 3/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0710 - acc: 0.9790    \n",
      "Epoch 4/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0654 - acc: 0.9801    \n",
      "Epoch 5/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0552 - acc: 0.9825    \n",
      "Epoch 6/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0574 - acc: 0.9827    \n",
      "Epoch 7/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0546 - acc: 0.9830    \n",
      "Epoch 8/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0523 - acc: 0.9830    \n",
      "Epoch 1/8\n",
      "42000/42000 [==============================] - 42s - loss: 0.0484 - acc: 0.9847    \n",
      "Epoch 2/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0508 - acc: 0.9846    \n",
      "Epoch 3/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0491 - acc: 0.9855    \n",
      "Epoch 4/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0473 - acc: 0.9840    \n",
      "Epoch 5/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0411 - acc: 0.9870    \n",
      "Epoch 6/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0417 - acc: 0.9868    \n",
      "Epoch 7/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0427 - acc: 0.9868    \n",
      "Epoch 8/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0450 - acc: 0.9863    \n",
      "Epoch 1/1\n",
      "42000/42000 [==============================] - 42s - loss: 0.3137 - acc: 0.9051    \n",
      "Epoch 1/4\n",
      "42000/42000 [==============================] - 41s - loss: 0.1223 - acc: 0.9624    \n",
      "Epoch 2/4\n",
      "42000/42000 [==============================] - 42s - loss: 0.1004 - acc: 0.9692    \n",
      "Epoch 3/4\n",
      "42000/42000 [==============================] - 41s - loss: 0.0887 - acc: 0.9733    \n",
      "Epoch 4/4\n",
      "42000/42000 [==============================] - 42s - loss: 0.0765 - acc: 0.9764    \n",
      "Epoch 1/8\n",
      "42000/42000 [==============================] - 42s - loss: 0.0722 - acc: 0.9781    \n",
      "Epoch 2/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0695 - acc: 0.9789    \n",
      "Epoch 3/8\n",
      "42000/42000 [==============================] - 42s - loss: 0.0616 - acc: 0.9812    \n",
      "Epoch 4/8\n",
      "42000/42000 [==============================] - 42s - loss: 0.0594 - acc: 0.9821    \n",
      "Epoch 5/8\n",
      "42000/42000 [==============================] - 42s - loss: 0.0618 - acc: 0.9817    \n",
      "Epoch 6/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0544 - acc: 0.9834    \n",
      "Epoch 7/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0538 - acc: 0.9840    \n",
      "Epoch 8/8\n",
      "42000/42000 [==============================] - 42s - loss: 0.0537 - acc: 0.9844    \n",
      "Epoch 1/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0493 - acc: 0.9843    \n",
      "Epoch 2/8\n",
      "42000/42000 [==============================] - 42s - loss: 0.0493 - acc: 0.9849    \n",
      "Epoch 3/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0450 - acc: 0.9865    \n",
      "Epoch 4/8\n",
      "42000/42000 [==============================] - 42s - loss: 0.0474 - acc: 0.9857    \n",
      "Epoch 5/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0455 - acc: 0.9858    \n",
      "Epoch 6/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0438 - acc: 0.9867    \n",
      "Epoch 7/8\n",
      "42000/42000 [==============================] - 41s - loss: 0.0428 - acc: 0.9869    \n",
      "Epoch 8/8\n",
      "42000/42000 [==============================] - 42s - loss: 0.0389 - acc: 0.9881    \n"
     ]
    }
   ],
   "source": [
    "models = [fit_model() for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, m in enumerate(models):\n",
    "    m.save_weights('data/mnist/cnn-mnist-noval-' + str(i) + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = np.array([m.predict(X_test, batch_size=256) for m in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.max(predictions, axis=0)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.argmax(labels, axis=1)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imageIds = np.arange(1, len(labels) + 1)\n",
    "imageIds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [2, 0],\n",
       "       [3, 9],\n",
       "       [4, 0],\n",
       "       [5, 3]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm = np.stack([imageIds, labels], axis=1)\n",
    "subm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm_filename = 'subm.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(subm_filename, subm, fmt='%d,%d', header='ImageId,Label', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='subm.csv' target='_blank'>subm.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/nbs/deep-learning/subm.csv"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(subm_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
